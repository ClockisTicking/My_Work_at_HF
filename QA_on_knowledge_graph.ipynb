{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOuJTqeixC16lo5JkTWycxE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ClockisTicking/My_Work_at_HF/blob/main/QA_on_knowledge_graph.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ! pip install gradio\n",
        "# ! pip install --upgrade pip\n",
        "# ! pip install git+https://github.com/deepset-ai/haystack.git#egg=farm-haystack[colab,inmemorygraph]"
      ],
      "metadata": {
        "id": "_rR-8pFJq4uR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "import gradio as gr\n",
        "from haystack.utils import fetch_archive_from_http\n",
        "from pathlib import Path\n",
        "from haystack.document_stores import InMemoryKnowledgeGraph\n",
        "from haystack.nodes import Text2SparqlRetriever\n",
        "\n",
        "\n",
        "logging.basicConfig(format=\"%(levelname)s - %(name)s -  %(message)s\", level=logging.WARNING)\n",
        "logging.getLogger(\"haystack\").setLevel(logging.INFO)"
      ],
      "metadata": {
        "id": "1fVTgBDMlzqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's first fetch some triples that we want to store in our knowledge graph\n",
        "# Here: exemplary triples from the wizarding world\n",
        "graph_dir = \"data/tutorial10\"\n",
        "s3_url = \"https://fandom-qa.s3-eu-west-1.amazonaws.com/triples_and_config.zip\"\n",
        "fetch_archive_from_http(url = s3_url, output_dir = graph_dir)\n",
        "\n",
        "# Fetch a pre-trained BART model that translates text queries to SPARQL queries\n",
        "model_dir = \"../saved_models/tutorial10_knowledge_graph/\"\n",
        "s3_url = \"https://fandom-qa.s3-eu-west-1.amazonaws.com/saved_models/hp_v3.4.zip\"\n",
        "fetch_archive_from_http(url = s3_url, output_dir = model_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfTpepdlmHMG",
        "outputId": "1632f99c-bba8-40c1-ebdc-6fd2816907db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:haystack.utils.import_utils:Found data stored in 'data/tutorial10'. Delete this first if you really want to fetch new data.\n",
            "INFO:haystack.utils.import_utils:Found data stored in '../saved_models/tutorial10_knowledge_graph/'. Delete this first if you really want to fetch new data.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kg = InMemoryKnowledgeGraph(index = \"tutorial_10_index\")\n",
        "\n",
        "# Delete the index as it might have been already created in previous runs\n",
        "kg.delete_index()\n",
        "\n",
        "# Create the index\n",
        "kg.create_index()\n",
        "\n",
        "# Import triples of subject, predicate, and object statements from a ttl file\n",
        "kg.import_from_ttl_file(index = \"tutorial_10_index\", path = Path(graph_dir) / \"triples.ttl\")\n",
        "print(f\"The last triple stored in the knowledge graph is: {kg.get_all_triples()[-1]}\")\n",
        "print(f\"There are {len(kg.get_all_triples())} triples stored in the knowledge graph.\")\n",
        "kgqa_retriever = Text2SparqlRetriever(knowledge_graph = kg, model_name_or_path = Path(model_dir) / \"hp_v3.4\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BfsbQAWvsDjd",
        "outputId": "b12ed4be-cd68-4b3c-843f-1dbc6962af99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The last triple stored in the knowledge graph is: {'s': {'type': 'uri', 'value': 'https://deepset.ai/harry_potter/Wizards_chess'}, 'p': {'type': 'uri', 'value': 'https://deepset.ai/harry_potter/owners'}, 'o': {'type': 'uri', 'value': 'https://deepset.ai/harry_potter/Harry_potter'}}\n",
            "There are 118543 triples stored in the knowledge graph.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kg"
      ],
      "metadata": {
        "id": "cnjeixu3aHOj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8af828b-49f4-4991-bed1-c2681a569890"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<haystack.document_stores.memory_knowledgegraph.InMemoryKnowledgeGraph at 0x7f734a773af0>"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kgqa_retriever.retrieve"
      ],
      "metadata": {
        "id": "gR-nTFT9lJy4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7a68791-4252-48fc-df4f-9b0c138d507e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Text2SparqlRetriever.retrieve of <haystack.nodes.retriever.text2sparql.Text2SparqlRetriever object at 0x7f736c0a9310>>"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BartForConditionalGeneration, BartTokenizer\n",
        "\n",
        "\n",
        "def get_sparql(query, top_k):\n",
        "  model = BartForConditionalGeneration.from_pretrained(\n",
        "            Path(model_dir) / \"hp_v3.4\", forced_bos_token_id = 0)\n",
        "  tok = BartTokenizer.from_pretrained(Path(model_dir) / \"hp_v3.4\")\n",
        "  inputs = tok([query], max_length=100, truncation=True, return_tensors=\"pt\")\n",
        "        # generate top_k+2 SPARQL queries so that we can dismiss some queries with wrong syntax\n",
        "  temp = model.generate(\n",
        "            inputs[\"input_ids\"], num_beams = 5, max_length = 100, num_return_sequences = top_k + 2, early_stopping = True\n",
        "        )\n",
        "  sparql_queries = [\n",
        "            tok.decode(g, skip_special_tokens = True, clean_up_tokenization_spaces = False) for g in temp\n",
        "        ]\n",
        "  return sparql_queries\n",
        "  \n"
      ],
      "metadata": {
        "id": "diD1h0cKhKMs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import result_type\n",
        "def get_res(query, top_k = 3):\n",
        "  returned_res = []\n",
        "  results = kgqa_retriever.retrieve(query = query, top_k = top_k)\n",
        "\n",
        "  for res in results:\n",
        "    returned_res.append(\"https://harrypotter.fandom.com/wiki/\" + res['answer'][0].split(\"/\")[-1].replace(\"potter\", \"Potter\").replace(\"r_i\", \"r_I\"))\n",
        "  returned_res = set(returned_res)\n",
        "  returned_res = list(returned_res)\n",
        "  return returned_res\n",
        "\n",
        "def get_query(query, top_k = 3):\n",
        "  returned_res = []\n",
        "  results = kgqa_retriever.retrieve(query = query, top_k = top_k)\n",
        "  for res in results:\n",
        "    returned_res.append(res[\"prediction_meta\"]['sparql_query'])\n",
        "  return \"\\n\".join(returned_res)\n",
        "  \n",
        "\n",
        "def get_file():\n",
        "  file_loc = \"/content/data/tutorial10/triples.ttl\"\n",
        "  f = open(file_loc, \"r\")\n",
        "  lines = f.readlines()\n",
        "  return \" \".join(lines[10:])"
      ],
      "metadata": {
        "id": "ZpkfdkOrv0AP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_res(\"In which house is Harry Potter?\", 3)"
      ],
      "metadata": {
        "id": "hlTNiBYUm3pX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "398da69e-d009-4056-ae20-cead90d0f368"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['https://harrypotter.fandom.com/wiki/Slytherin',\n",
              " 'https://harrypotter.fandom.com/wiki/Gryffindor']"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "demo = gr.Blocks()\n",
        "\n",
        "with demo:\n",
        "    gr.Markdown(\"\"\"# Q/A with Knowledge graph\n",
        "                Querying knowledge graphs with the help of pre-trained models that translate text queries to SPARQL queries\"\"\")\n",
        "    gr.HTML(\"<img src = 'file=/content/graph_sanple.png'/>\")\n",
        "    with gr.Tabs():\n",
        "        with gr.TabItem(\"The Demo\"):\n",
        "            with gr.Row():\n",
        "                text_input = gr.Textbox(label = \"Input question\")\n",
        "                with gr.Column():\n",
        "                  Answer = gr.Textbox(label = \"Answers\")\n",
        "                  Sparql = gr.Textbox(label = \"Sparql\")\n",
        "            \n",
        "            answer_button = gr.Button(\"Get Answer\")\n",
        "            sparql_button = gr.Button(\"Get Sparql\")\n",
        "            gr.Examples(examples = [[\"in which house is Harry Potter\"], [\"who's harry potter's grandfather\"], [\"What is the patronus of Hermione\"]], inputs = text_input, outputs = Answer)\n",
        "        \n",
        "        with gr.TabItem(\"The knowledge Triplet\"):  \n",
        "          triplet = gr.Textbox(label = \"The knowledge Graph Triplets\", lines = 10)\n",
        "          KG_button = gr.Button(\"Get Triplets\")\n",
        "\n",
        "    answer_button.click(get_res, inputs = text_input, outputs = Answer)\n",
        "    sparql_button.click(get_query, inputs = text_input, outputs = Sparql)\n",
        "    KG_button.click(get_file, outputs = triplet)\n",
        "demo.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 618
        },
        "id": "UQkZooJ9uj0j",
        "outputId": "75b8d5ed-1ced-484d-ce9a-be26b7b57b62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Note: opening Chrome Inspector may crash demo inside Colab notebooks.\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "                        if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "                            return;\n",
              "                        }\n",
              "                        element.appendChild(document.createTextNode(''));\n",
              "                        const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "\n",
              "                        const external_link = document.createElement('div');\n",
              "                        external_link.innerHTML = `\n",
              "                            <div style=\"font-family: monospace; margin-bottom: 0.5rem\">\n",
              "                                Running on <a href=${new URL(path, url).toString()} target=\"_blank\">\n",
              "                                    https://localhost:${port}${path}\n",
              "                                </a>\n",
              "                            </div>\n",
              "                        `;\n",
              "                        element.appendChild(external_link);\n",
              "\n",
              "                        const iframe = document.createElement('iframe');\n",
              "                        iframe.src = new URL(path, url).toString();\n",
              "                        iframe.height = height;\n",
              "                        iframe.allow = \"autoplay; camera; microphone; clipboard-read; clipboard-write;\"\n",
              "                        iframe.width = width;\n",
              "                        iframe.style.border = 0;\n",
              "                        element.appendChild(iframe);\n",
              "                    })(7873, \"/\", \"100%\", 500, false, window.element)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    }
  ]
}